# UMamba 图学习优化总结

## 概述
将 UMamba 从纯序列模型升级为 **图增强的时空模型**，充分利用 DGCRN 的图学习能力，同时保留 Mamba 的序列建模优势。

## 核心改进

### 1. **动态图学习模块** (`DynamicGraphLearning`)
- **灵感来源**: DGCRN 的动态图学习机制
- **实现**:
  - 学习节点嵌入向量 (emb1, emb2)，参数量与节点数成正比
  - 通过这两个嵌入的乘积差计算节点间的关系强度
  - 使用 tanh 激活和可配置的缩放因子 (tanhalpha)
  - 输出归一化的邻接矩阵 (行和为1的随机游走矩阵)
- **优势**:
  - 完全可学习的图结构，能根据数据自适应
  - 与 DGCRN 一致的图学习方式

### 2. **图卷积层** (`GCNLayer`)
- **功能**: 在节点维度上进行图卷积，实现空间消息传递
- **实现**:
  - 使用 einsum 操作进行高效的图卷积: `(B, N, T, C) @ (N, N) -> (B, N, T, C)`
  - 保持时间和特征维度不变，只在空间维度上聚合
- **计算复杂度**: $O(N^2 \cdot T \cdot C)$

### 3. **空间注意力机制** (`SpatialAttention`)
- **功能**: 学习节点间的动态权重分配
- **实现**:
  - 多头注意力机制，在节点维度上计算
  - 根据查询和键的相似性学习注意力权重
  - 在节点维度上进行 softmax，确保权重分配的合理性
- **优势**: 比固定的图卷积更灵活

### 4. **改进的编码器块** (`EncoderBlock`)
- **新增功能**:
  - 条件式图卷积：当邻接矩阵可用时应用
  - 空间注意力融合
  - 时间 Mamba 建模和空间图卷积的联合学习
- **架构**:
  ```
  输入 -> Mamba(时间) -> 图卷积(空间) + 空间注意力(空间)
       -> 降采样 -> 输出
  ```
- **优势**: 真正的时空联合建模

### 5. **改进的解码器块** (`DecoderBlock`)
- **新增功能**:
  - 在上采样后融合空间特征
  - 条件式图卷积和空间注意力
- **架构**:
  ```
  输入 -> 上采样 -> 特征融合 -> Mamba(时间) 
       -> 图卷积(空间) + 空间注意力(空间) -> 输出
  ```

### 6. **改进的主模型** (`UMamba`)
- **新增参数**:
  - `use_graph_learning`: 启用/禁用图学习
  - `node_dim`: 节点嵌入维度
  - `tanhalpha`: 图学习中的缩放因子
- **改进的前向传播**:
  - 在每个编码/解码块传入学到的邻接矩阵
  - 在瓶颈层也添加图卷积和空间注意力
  - 真正的时空联合建模

## 配置参数优化

### 原始参数 vs 新参数

| 参数 | 原始值 | 新值 | 说明 |
|-----|-------|-----|------|
| n_mamba_per_block | 3 | 2 | 降低时间建模复杂度，因为加入了空间建模 |
| d_model | 64 | 64 | 保持不变（足够好） |
| num_levels | 3 | 3 | 保持不变 |
| step_size (LR schedule) | 10 | 5 | 加快学习率衰减，因为参数更多 |
| lrate (初始学习率) | 1e-3 | 5e-4 | 降低初始学习率，稳定训练 |
| **新增参数** | | | |
| node_dim | - | 32 | 节点嵌入维度，与d_model相关 |
| use_graph_learning | - | True | 启用动态图学习 |
| tanhalpha | - | 3.0 | 图学习中的缩放因子 |

## 内存和计算复杂度分析

### 参数数量增加
- **动态图学习**: $2 \times N \times node\_dim$ 个参数
- **空间注意力**: 在编码器、解码器和瓶颈处各增加 $4 \times d\_model^2$ 个参数
- **GCN层**: 无额外参数（使用已学到的邻接矩阵）

### 总体复杂度
- **时间复杂度**: $O(N^2 \cdot T \cdot L)$ (N 是节点数, T 是时间步长, L 是 Mamba 层数)
  - 相比纯序列模型增加了 $O(N^2)$ 的图卷积
  - 对于中等规模的交通网络（N < 1000）可以接受

### 显存需求
- 图卷积和注意力会增加中间激活的显存
- 整体增加约 20-30%（取决于 N 的大小）

## 期望改进

### 相比纯 UMamba
1. **空间一致性**: 通过图卷积和空间注意力，相邻节点的预测会更加一致
2. **长期依赖**: DGCRN 的动态图学习能够捕捉复杂的空间模式
3. **泛化能力**: 图结构的归纳偏好有助于泛化到未见的数据

### 相比 DGCRN
1. **多尺度时空特征**: U-Net 结构的多尺度特征提取
2. **灵活的序列建模**: Mamba 比 RNN 更高效
3. **特征融合**: 跳跃连接和多层级解码

## 使用方法

### 1. 启用图学习（默认）
```bash
python main.py --dataset <dataset> --use_graph_learning True
```

### 2. 调整超参数
```bash
python main.py --dataset <dataset> \
    --node_dim 32 \
    --tanhalpha 3.0 \
    --lrate 5e-4 \
    --step_size 5
```

### 3. 禁用图学习（回到纯 UMamba）
```bash
python main.py --dataset <dataset> --use_graph_learning False
```

## 可进一步优化的方向

1. **预定义图结构**: 可选择提供预定义的邻接矩阵（如距离矩阵）
2. **多图融合**: 同时学习多个图结构并融合
3. **自适应图稀疏化**: 限制图中的连接数量
4. **时间相关的图**: 让邻接矩阵随时间变化
5. **图注意力网络 (GAT)**: 用 GAT 替代简单的 GCN

## 文件变更

- **umamba_model.py**: 
  - 新增 4 个模块类
  - 改进的 EncoderBlock, DecoderBlock, UMamba
  - 总代码行数增加约 200 行

- **main.py**:
  - 新增参数配置
  - 改进的超参数设置
  - 模型初始化更新

## 与 DGCRN 的关键差异

| 特性 | DGCRN | 改进的 UMamba |
|-----|-------|-------------|
| 时间建模 | GRU/LSTM | Mamba (SSM) |
| 图学习方式 | 相同 | 相同 |
| 编码器 | 单层递归 | U-Net 多尺度 |
| 解码器 | 单层递归 + 课程学习 | U-Net 多尺度 + 跳跃连接 |
| 计算效率 | 低 (RNN 顺序) | 高 (Mamba 并行) |
| 显存占用 | 中等 | 中等-高 |

---

**更新日期**: 2025-11-24
**版本**: 1.0
